---
title: "Authors Response to Reviewers"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## *Binning Strategies and Related Loss for Binned Scatterplots of Large Data*

The following document strives to address comments, questions and concerns made by the reviewers on a point-by-point basis. The reviewer statement are included verbatim through *italic text blocks*; our responses are interspersed to address each point more directly. In the revised article that accompanies, the edits are made in red text to make changes more easily identifiable. The revisions will be reverted to black after the revision process.  

### Responses to Reviewer 1 Comments/Questions

*The authors discuss different binning strategies and the resulting aggregation- induced errors. Both errors, loss of spatial resolution and loss of frequency information are introduced and formalized. Binning is an important preprocessing step and research in this area is highly relevant. However, there are some major points missing, making this work less convincing.*

*The most crucial point is in my opinion the missing discussion of the influence of different data distributions. In the visualization community exists research on different descriptors for two-dimensional data called Scagnostics. When I started reading this article, I expected a thorough discussion of different data distributions/properties and the influence on different binning strategies and error outcomes.*

- We are very grateful that the review brought the literature on scagnostics to our attention; the work and scagnostic metrics formalized in the works by Wilkerson, Anand, Grosmann and Wills will be valuable to the discussion of binned scatterplots. Specifically scagnostic literature contributes to Section 5 of our paper in the exploration of loss under a variety of simulated distribution. You will find that a discussion of the relevance of scagnostics has been added immediately preceeding the start of subsection 5.1. It is interesting that the striation score is so small, given that the data resolution issue can lead to artificially induced stripping is seen in so prominently in Figure 6.

*In Section 4.2, a discussion on contrast effects hindering the perception of the encoded values is missing. Nearby colored points, will change the color impression. These effects can be modelled and estimated and maybe interesting to investigate a little further.*

*As a computer scientist, it is not clear to me, why the runtime is larger with lower numbers of bins (Section 5.1. lines 33ff.)  In my naïve implementation, I would iterate once over all data points and assign the respective bins by an adopted integer division. Consequently, the runtime would be in O(n d) with n being the number of data points and d the number of dimensions. Maybe, the authors could explain the runtime experiments more or discuss the used algorithm more. If the number of bins is 1, I would expect the fastest runtime.*

- Your intuition is correct, but there was a misunderstanding about Figure 5. The x-axis relates the the *size* of bins not the *number* of bins, meaning that the binning takes less time as the bin widths grows (ie the number of bins decreases). x=1 means using many 1X1 bins, not one large bin. The x-axis label has been edited to more clearly reflect that this is the size of the bin dimensions. 

*In the application example, why are 50 bins chosen and why is standard rectangular binning chosen? How would other binning results differ from the presented binning. The different variants in Figure 11 are only different color mappings of density. I would include here a discussion of data properties (Scagnostics) together with some error measurements described by the authors beforehand.*

- The beginning of section 5.3 has been rewritten to more explicitly tie the binning choices for the baseball example to the lessons learned in 5.1 and 5.2. 

*Minor remarks:Add color legend to Figure 7*

- Added as per request.

### Responses to Reviewer 2 Comments/Questions

*This paper reviews visualization methods for scatterplots and their strengths and weaknesses in handling large datasets. Section 2 notes that binned aggregation is the most widely used and effective way to visualize big bivariate data. In Section 3, the paper introduces three types of binning algorithms: standard rectangular, random and quantile. The main idea in this paper is presented in Section 4, where loss of information is characterized using two metrics: spatial loss and frequency loss. Spatial loss accounts for the loss of information about each individual point’s location; and frequency loss addresses the limitation of human perception in distinguishing frequencies represented using hues or saturation. Section 5 then presents some empirical results on how various factors may affect spatial loss and frequency loss based on three synthetic datasets. These factors include bin width and bin origin for spatial loss, and number of bins for frequency loss.*

*In general, I think this paper addresses an important topic. Guidelines on choosing binning algorithms will be immensely helpful for practitioners dealing with big data. I am, however, reserved in recommending acceptance because of two main concerns: lack of novelty and unconvincing results.*

*Lack of Novelty:*
*Section 2 and 3 do a good job in reviewing the concepts of binned aggregation and varieties of binning algorithms. However these are fairly well known and the discussion does not seem to contribute novel ideas. The only thing that I haven’t seen before is the random binning approach. Is this a new idea proposed by you? If so, please state clearly. I also wonder how and why random binning can be useful. Please provide scenarios in which it would make sense to use random binning.* 

*For the other ideas covered in these two sections, please properly cite relevant work.*

- You are correct that many of the ideas in Sections 2 and 3 are not original, with the exception of the random binning approach, where the methodology for random-binned aggregation is original to my best knowledge. The goal of these sections is to bring many binning related concepts under a unified notation for the benefit of clarity in the sections to follow. For the random binning, a statement has been added to address the motivation for its introduction: deterministic one-sided interval bins lead to lopsided allocation of points on bin boundaries, whereas a random assignment is expected to split the points evenly across bins. For the unoriginal ideas, additional citations have been made to place the unifying notation better within the existing literature. 

*Unconvincing Results:*
*In Section 4.1, you propose the idea of spatial loss as a metric to account for the loss of information. Please explain how this approach is related to Scott’s approach of using mean integrated square error. What makes your definition a better choice?*

- The comparison and benefit over Scotts MISE is not included to the discussion leading into Section 4. 

*I do not understand how binned frequencies (as compared to true frequencies) are calculated in Section 4.2 on frequency loss. Please provide an example. Also please clarify is binned frequencies are measures of frequencies perceived by a human.*

*The first paragraph of Section 5.1 shows that spatial loss increases as bin size increases, this seems hardly surprising. In the second paragraph, you talk about three properties of visual estimator: unbiasedness, consistency and efficiency, I think these properties are interesting, but the rest of the paper does not address them sufficiently.*

*I also fail to understand how the discussion on artificial striping in Section 5.1 is relevant for spatial loss.*

*Please provide quantified results on spatial loss when you talk about how binning origin affects spatial loss in Figure 7.*

*In visualization practices, it is common to use both ordinal scales as well as continuous scales when mapping numbers to colors. How might you address the issue of frequency loss when continuous scales are used?*

*I don’t buy the advice to “use between four and seven frequency”. There simply isn’t empirical evidence in the paper to support this claim.*

*From a human-computer interaction perspective, it is also limiting when the paper talks about spatial loss and frequency loss without any mention of user tasks (e.g. comparison, outlier detection). Do these metric matter for all the tasks involved in reading the scatterplots?*

